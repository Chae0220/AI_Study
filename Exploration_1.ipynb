{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b1bfa4",
   "metadata": {},
   "source": [
    "# EXPLORATION_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcece43",
   "metadata": {},
   "source": [
    "#### 모듈 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f7250718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import  classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702ad03",
   "metadata": {},
   "source": [
    "## 1. digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9ebd7",
   "metadata": {},
   "source": [
    "### 1.1 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c248e",
   "metadata": {},
   "source": [
    "1) load_digits 를 통해 데이터를 불러오면 7개의 key 값을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d2e3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "print(digits.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e73cbe1",
   "metadata": {},
   "source": [
    "2) 'DESCR'은 데이터의 설명을 기재한 항목으로 가장 우선적으로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8018066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00760f43",
   "metadata": {},
   "source": [
    "3) 데이터 요약  \n",
    " - 인스턴스 수 : 1797  \n",
    " - 속성 수 : 64  \n",
    " - 속성정보 : 0~16 사이의 정수이며, 8x8 픽셀  \n",
    " - 결측치 : 없음  \n",
    " - 만든이 : E. Alpaydin  \n",
    " - 날짜 : 7월, 1998년\n",
    " - 특징 : 필기체로 작성된 숫자 데이터 세트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90823a9",
   "metadata": {},
   "source": [
    "4) data를 상세하게 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef75e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "digits_data = digits.data\n",
    "print(digits_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53339989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee11ac",
   "metadata": {},
   "source": [
    "- data는 총 1797개가 있고 각 데이터는 64개의 숫자로 이루어져있음.  \n",
    "- array를 보면 픽셀값이라고 생각이 들지만 확인 필요\n",
    "- pandas의 DataFrame으로 변환하여 column을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83bc8213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
      "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
      "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
      "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
      "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
      "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
      "\n",
      "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
      "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
      "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
      "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "\n",
      "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
      "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
      "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
      "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
      "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
      "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
      "\n",
      "   pixel_7_6  pixel_7_7  \n",
      "0        0.0        0.0  \n",
      "1        0.0        0.0  \n",
      "2        9.0        0.0  \n",
      "3        0.0        0.0  \n",
      "4        0.0        0.0  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "digits_df = pd.DataFrame(data=digits.data, columns=digits.feature_names)\n",
    "print(digits_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3195d2d",
   "metadata": {},
   "source": [
    "- 이미지인지 확인하기 위해 matplotlib 라이브러리를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ae22a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAADyUlEQVR4nO3dUVFjaRRG0T9TYyAWggSwkkgACSABL5FAJBALSCAS7higeZo6vZte6zF5+KiEXbeKB85u27YF9Pzzu38A4GvihChxQpQ4IUqcEPXvd2/udrsf+afc4/E4uvf6+jq2dblcxrZeXl7Gtm6329jWtG3bdl+97skJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqG/PMfxUk+cR1lrrcDiMbe33+7Gtz8/Psa3T6TS2tdZa5/N5dO8rnpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IypxjuL+/H9uaPI+w1lp3d3djWx8fH2Nbb29vY1uTvx9rOccAfEOcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiMrcStnv92Nb1+t1bGut2fslk6Y/x7+NJydEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi/spzDJfLZWzrJ5v8zm6329hWhScnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTojLnGCb/3f79/f3Y1rTJEwmTn+P5fB7bqvDkhChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtRu27Zfv7nb/frN/9nhcJiaWu/v72Nba6319PQ0tnU8Hse2Jr+zh4eHsa1p27btvnrdkxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSozK2USY+Pj6N7z8/PY1vX63Vs63Q6jW39ZG6lwB9GnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBD17TkG4Pfx5IQocUKUOCFKnBAlTogSJ0T9ByioUst9Wxj9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.data[0].reshape(8, 8), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4ca40b",
   "metadata": {},
   "source": [
    "- 이미지 확인을 했으나 숫자 0인지 알파벳 o인지 한글 ㅇ인지 알 수 없음  \n",
    "- 다른 데이터도 확인이 필요  \n",
    "- subplot을 이용해 2줄 5개의 데이터를 한번에 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f01b532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8, 8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8fa391",
   "metadata": {},
   "source": [
    " - 숫자 데이터임을 확인했으므로 이에 따른 모델 학습목표 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50acaf26",
   "metadata": {},
   "source": [
    "### 1.2 목표 설정\n",
    " - 데이터셋을 통해 학습 후 임의의 정수형 숫자 손글씨 데이터를 입력받아 해당 숫자를 출력하는 모델을 만들자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1628c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "==================================\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "digits_labels = digits.target\n",
    "print(digits_data)\n",
    "print(\"==================================\")\n",
    "print(digits_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d28a39",
   "metadata": {},
   "source": [
    " - 데이터셋 확인을 위해 digits_data에 저장, Label Data 지정\n",
    "라벨을 살펴보면 target_names는 0~9까지라 예상된다. 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c5c5a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacb7548",
   "metadata": {},
   "source": [
    "### 1.3 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d143d",
   "metadata": {},
   "source": [
    "1) 학습 데이터 준비\n",
    "- 학습을 위해 train, test set으로 분리  \n",
    "  모델에 입력할 데이터는 X, 비교할 정답 데이터는 y, 학습 데이터는 train, 테스트 데이터는 test로 분리  \n",
    "  data_size=0.2로 테스트용 데이터는 20%로 구성하고 random_state 값을 통해 분리할 때 데이터를 랜덤 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "324fcdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64) (1437,)\n",
      "(360, 64) (360,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state=15)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833442a8",
   "metadata": {},
   "source": [
    "- .shape로 데이터가 잘 나뉘었는지 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc1aaab",
   "metadata": {},
   "source": [
    "2) 모델 적용\n",
    "- 어떤 모델이 적합한지 확인이 필요하므로 5가지 모델을 다 적용해 본다.  \n",
    "  (Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression)  \n",
    "- 모델의 평가는 sklearn의 Classification_report를 import하여 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2083a",
   "metadata": {},
   "source": [
    "1) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2dcdf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93        31\n",
      "           1       0.76      0.84      0.80        38\n",
      "           2       0.94      0.87      0.90        38\n",
      "           3       0.75      0.78      0.76        27\n",
      "           4       0.97      0.83      0.89        41\n",
      "           5       0.85      0.97      0.91        35\n",
      "           6       0.85      0.89      0.87        38\n",
      "           7       0.82      0.94      0.88        34\n",
      "           8       0.72      0.66      0.69        35\n",
      "           9       0.88      0.81      0.84        43\n",
      "\n",
      "    accuracy                           0.85       360\n",
      "   macro avg       0.85      0.85      0.85       360\n",
      "weighted avg       0.85      0.85      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_digit = DecisionTreeClassifier(random_state=20)\n",
    "decision_tree_digit.fit(X_train, y_train)\n",
    "y_pred = decision_tree_digit.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89d906",
   "metadata": {},
   "source": [
    "2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db8a703a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        31\n",
      "           1       0.95      0.97      0.96        38\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      0.96      0.98        27\n",
      "           4       0.95      1.00      0.98        41\n",
      "           5       0.97      1.00      0.99        35\n",
      "           6       1.00      0.95      0.97        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.94      0.97      0.96        35\n",
      "           9       1.00      0.98      0.99        43\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_digit = RandomForestClassifier(random_state=32)\n",
    "random_forest_digit.fit(X_train, y_train)\n",
    "y_pred = random_forest_digit.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e501983",
   "metadata": {},
   "source": [
    "3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f8b26e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.95      1.00      0.97        38\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       0.96      0.96      0.96        27\n",
      "           4       0.98      0.98      0.98        41\n",
      "           5       1.00      1.00      1.00        35\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.97      0.94      0.96        35\n",
      "           9       0.98      0.98      0.98        43\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model_digit = svm.SVC()\n",
    "svm_model_digit.fit(X_train, y_train)\n",
    "y_pred = svm_model_digit.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1111724",
   "metadata": {},
   "source": [
    "4) SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8c5b8586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        31\n",
      "           1       0.97      0.82      0.89        38\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       1.00      0.85      0.92        27\n",
      "           4       0.93      1.00      0.96        41\n",
      "           5       0.97      1.00      0.99        35\n",
      "           6       1.00      0.92      0.96        38\n",
      "           7       0.94      1.00      0.97        34\n",
      "           8       0.77      0.94      0.85        35\n",
      "           9       0.91      0.95      0.93        43\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.95      0.94      0.94       360\n",
      "weighted avg       0.95      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model_digits = SGDClassifier()\n",
    "sgd_model_digits.fit(X_train, y_train)\n",
    "y_pred = sgd_model_digits.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbf84d",
   "metadata": {},
   "source": [
    "5) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a0e6196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        31\n",
      "           1       0.95      0.97      0.96        38\n",
      "           2       1.00      0.97      0.99        38\n",
      "           3       0.96      0.93      0.94        27\n",
      "           4       0.93      1.00      0.96        41\n",
      "           5       0.94      0.97      0.96        35\n",
      "           6       1.00      0.97      0.99        38\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.94      0.94      0.94        35\n",
      "           9       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losistic_model_digits = LogisticRegression(max_iter=5000)\n",
    "losistic_model_digits.fit(X_train, y_train)\n",
    "y_pred = losistic_model_digits.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067de842",
   "metadata": {},
   "source": [
    "### 1.4 결과분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283872e",
   "metadata": {},
   "source": [
    "classification report에 아래와 같은 내용들이 나온다.\n",
    " - Precision은 Confusion matrix에서 TP / TP + FP이다.(양성으로 예측한 샘플 중 실제 양성인 비율)\n",
    " - Recall은 TP / TP + FN(실제 양성 중 양성이라고 예측한 비율)\n",
    " - Accuracy는 TP + TN / TN + TP + FN + FP (전체 샘플 중 맞게 예측한 샘플 수의 비율)\n",
    " - F1-score는 precision과 recall의 가중 조화평균이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aebc0f1",
   "metadata": {},
   "source": [
    "- 가장 먼저 Accuracy로 탈락시킬 모델이 보인다. - Decision tree  \n",
    "  약 85%의 정확도로 나머지 모델에 비해 터무니 없이 낮다.  \n",
    "  Decision tree의 단점 중 하나인 과적합으로 인해 정확도가 떨어진 것이라 판단된다.\n",
    "    \n",
    "    \n",
    "- Stochastic Gradient Descent는 20번 수행했을 때 정확도가 들쑥날쑥한 모습(0.91~0.96)을 보여준다.  \n",
    "  이는 랜덤 추출한 일부 데이터에 대해 가중치를 조절했기 때문이라고 판단된다.  \n",
    "    \n",
    "    \n",
    "- 나머지 모델들은 사실 어떤 것을 고르더라도 큰 차이는 없을 것으로 보인다.  \n",
    "  \n",
    "    \n",
    "- Logistic Regression의 경우 iter_max의 사이즈가 지정되어 있어 오류 메시지를 보여준다.   \n",
    "  (max_iter=10)를 통해 iter 값을 바꿀 수 있다. 반복 횟수(iter) 10회 미만일 때는 성능 편차가 크지만,   \n",
    "  10회를 넘어갈수록 성능 변화가 미미함 따라서 가성비 있는 훈련은 10~20회 가량으로 판단되며,  \n",
    "  iterations reached limit warning message를 보고 싶지 않으면 max_iter 값을 5000정도 주어 훈련하는 것을 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c8503",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fff3af",
   "metadata": {},
   "source": [
    "# 2. Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08083e54",
   "metadata": {},
   "source": [
    "### 2.1 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49dc61a",
   "metadata": {},
   "source": [
    "1) load_wine 를 통해 데이터를 불러오면 7개의 key 값을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "30c1c41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "print(wine.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838e0307",
   "metadata": {},
   "source": [
    "2) 'DESCR'은 데이터의 설명을 기재한 항목으로 가장 우선적으로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2f50675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e29f16",
   "metadata": {},
   "source": [
    "3) 데이터 요약  \n",
    " -  인스턴스 수 : 178(각각 50개씩 3개의 클래스로 구분)  \n",
    " -  속성 수 : 13개(Alcohol, Malic Acid, Ash 등...)  \n",
    " -  클래스 수 : 3개(class_0, class_1, class_2)  \n",
    " -  결측치 : 없음  \n",
    " -  만든이 : R.A. Fisher  \n",
    " -  생성일 : 7월, 1988년  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d47f5",
   "metadata": {},
   "source": [
    "4) data를 상세하게 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d07f5571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "wine_data = wine.data\n",
    "print(wine_data.shape)\n",
    "\n",
    "wine_targetnm = wine.target_names\n",
    "print(wine_targetnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f02bf",
   "metadata": {},
   "source": [
    "- 178개의 데이터로 13개 속성으로 나뉨\n",
    "- class_0, class_1, class_2 / 총 3개의 타겟으로 분류 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8c03f259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  \n",
      "0                          3.92   1065.0  \n",
      "1                          3.40   1050.0  \n",
      "2                          3.17   1185.0  \n",
      "3                          3.45   1480.0  \n",
      "4                          2.93    735.0  \n"
     ]
    }
   ],
   "source": [
    "wine_df = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "print(wine_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc458e78",
   "metadata": {},
   "source": [
    "- 'DESCR'를 통해 이미 13개의 속성이 무엇인지 알고 있지만, 확인 차원에서 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd054238",
   "metadata": {},
   "source": [
    "### 2.2 목표설정\n",
    " - 데이터셋의 13개의 속성을 통해 3개의 클래스로 분류 학습 후 다른 와인의 속성 값을 입력받으면 분류하는 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ca8a321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "==================================\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "wine_labels = wine.target\n",
    "print(wine_data)\n",
    "print(\"==================================\")\n",
    "print(wine_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfd7cd",
   "metadata": {},
   "source": [
    " - 학습을 위해 분류 전 마지막으로 Label Data 지정하고 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17caea",
   "metadata": {},
   "source": [
    "### 2.3 모델학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1c7eb",
   "metadata": {},
   "source": [
    "1) 학습 데이터 준비\n",
    "- 학습을 위해 train, test set으로 분리  \n",
    "  모델에 입력할 데이터는 X, 비교할 정답 데이터는 y, 학습 데이터는 train, 테스트 데이터는 test로 분리  \n",
    "  data_size=0.2로 테스트용 데이터는 20%로 구성하고 random_state 값을 통해 분리할 때 데이터를 랜덤 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b3d6d123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 71, 0: 59, 2: 48})\n",
      "Counter({1: 71, 0: 59, 2: 48})\n",
      "(142, 13) (142,)\n",
      "(36, 13) (36,)\n",
      "Counter({1: 71, 0: 59, 2: 48})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.2, random_state=15, stratify=wine_labels)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b3b28",
   "metadata": {},
   "source": [
    "- .shape로 데이터가 잘 나뉘었는지 확인(총 178개의 데이터가 142, 36개로 잘 나뉨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768340fa",
   "metadata": {},
   "source": [
    "2) 모델 적용\n",
    "- 어떤 모델이 적합한지 확인이 필요하므로 5가지 모델을 다 적용해 본다.  \n",
    "  (Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression)  \n",
    "- 모델의 평가는 sklearn의 Classification_report를 import하여 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6575f",
   "metadata": {},
   "source": [
    "1) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "08e9f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      0.93      0.96        14\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_wine = DecisionTreeClassifier(random_state=22)\n",
    "decision_tree_wine.fit(X_train, y_train)\n",
    "y_pred = decision_tree_wine.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca0641",
   "metadata": {},
   "source": [
    "2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c1e15820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      0.93      0.96        14\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_wine = RandomForestClassifier(random_state=32)\n",
    "random_forest_wine.fit(X_train, y_train)\n",
    "y_pred = random_forest_wine.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c8877",
   "metadata": {},
   "source": [
    "3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9a2a4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.67      1.00      0.80        14\n",
      "           2       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.81      0.74      0.73        36\n",
      "weighted avg       0.80      0.78      0.75        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model_wine = svm.SVC()\n",
    "svm_model_wine.fit(X_train, y_train)\n",
    "y_pred = svm_model_wine.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401ded3",
   "metadata": {},
   "source": [
    "4) SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "317afa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        12\n",
      "           1       1.00      0.29      0.44        14\n",
      "           2       0.43      1.00      0.61        10\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.81      0.68      0.64        36\n",
      "weighted avg       0.84      0.64      0.63        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model_wine = SGDClassifier()\n",
    "sgd_model_wine.fit(X_train, y_train)\n",
    "y_pred = sgd_model_wine.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb75347",
   "metadata": {},
   "source": [
    "5) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5ba6a486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        39\n",
      "           1       0.91      0.93      0.92        75\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.88      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losistic_model_wine = LogisticRegression(max_iter=5000)\n",
    "losistic_model_wine.fit(X_train, y_train)\n",
    "y_pred = losistic_model_wine.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e006d9",
   "metadata": {},
   "source": [
    "### 2.4 결과분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41d59cc",
   "metadata": {},
   "source": [
    "classification report에 아래와 같은 내용들이 나온다.\n",
    "\n",
    "- Precision은 Confusion matrix에서 TP / TP + FP이다.(양성으로 예측한 샘플 중 실제 양성인 비율)\n",
    "- Recall은 TP / TP + FN(실제 양성 중 양성이라고 예측한 비율)\n",
    "- Accuracy는 TP + TN / TN + TP + FN + FP (전체 샘플 중 맞게 예측한 샘플 수의 비율)\n",
    "- F1-score는 precision과 recall의 가중 조화평균이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb50c8f",
   "metadata": {},
   "source": [
    "- 우선 SVM 모델에서 F-score zreo_division 경고가 발생했다. 원인은 wine_labels을 train, test dataset으로 분류할 때 data의 수가 적어 비율에 맞춰 분류되지 않았다고 판단하였고 stratify로 분포 비율을 일정하게 유지시켰다.  \n",
    "  \n",
    "\n",
    "- 가장 먼저 Accuracy로 탈락시킬 모델이 보인다. - SVM, SGD Classifier  \n",
    "  이 두 모델은 데이터 수가 적은 경우에는 사용을 안하는 것이 좋겠다고 판단된다.  \n",
    "  앞서 진행한 digits 데이터의 경우 약 1,700건으로 wine 데이터의 10배 정도 크기였다.  \n",
    "  이에 따라 모델이 의미를 갖기 위해서는 적어도 1,000건이 넘는 인스턴스를 보유한 경우에만 사용하는 것이 좋겠다.\n",
    "  \n",
    "\n",
    "- 와인의 class를 분류하는 경우에는 정확도가 중요하다고 생각한다. Decision Tree, Random forest 둘 중 하나를 사용하여 모델을 만드는 것이 좋다고 생각하며 Logistic Regression의 경우 반복 횟수(iter) 42회 미만일 때는 성능 편차가 크지만, 42회를 넘어갈수록 성능 변화가 미미함 따라서 가성비 있는 훈련은 50~60회 가량으로 판단됨.  \n",
    "iterations reached limit warning message를 보고 싶지 않으면 max_iter 값을 5000정도 주어 훈련하는 것을 권장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c783591",
   "metadata": {},
   "source": [
    "ㅡ\n",
    "    \n",
    "     \n",
    "\n",
    "목표 : 13개의 속성을 통해 3개의 클래스로 분류 학습을 시키고, 다른 와인의 속성 값을 입력받으면 분류하여 클래스(품종)에 따라 출력하는 모델을 만든다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c645d",
   "metadata": {},
   "source": [
    "# 3. Breast cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b53732",
   "metadata": {},
   "source": [
    "### 3.1 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68dbb7",
   "metadata": {},
   "source": [
    "1) load_breast_cancer 를 통해 데이터를 불러오면 8개의 key 값을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35f98ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "print(cancer.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355efae",
   "metadata": {},
   "source": [
    "2) 'DESCR'은 데이터의 설명을 기재한 항목으로 가장 우선적으로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f974f20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c05be",
   "metadata": {},
   "source": [
    "3) 데이터 요약\n",
    "\n",
    " - 인스턴스 수 : 569개\n",
    " - 속성 수 : 30개(radius, texture 등...)\n",
    " - 클래스 수 : 2개(WDBC-Malignant, WDBC-Benign) / Malignant - 212, Benign - 357\n",
    " - 결측치 : 없음\n",
    " - 만든이 : Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
    " - 생성일 : 11월, 1995년"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58611948",
   "metadata": {},
   "source": [
    "4) data를 상세하게 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1408bf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "cancer_data = cancer.data\n",
    "print(cancer_data.shape)\n",
    "\n",
    "cancer_targetnm = cancer.target_names\n",
    "print(cancer_targetnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67fe586",
   "metadata": {},
   "source": [
    "- 569개의 데이터로 30개 속성으로 나뉨\n",
    "- malignant, benign/ 총 2개의 타겟으로 분류 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f675c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "cancer_df = pd.DataFrame(data=cancer.data, columns=cancer.feature_names)\n",
    "print(cancer_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ff131",
   "metadata": {},
   "source": [
    " - 'DESCR'를 통해 이미 30개의 속성이 무엇인지 알고 있지만, 확인 차원에서 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df1128",
   "metadata": {},
   "source": [
    "### 3.2 목표설정\n",
    " - 데이터셋의 30개의 속성을 통해 2개의 클래스로 분류 학습 후 다른 데이터를 입력받으면 분류하는 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "20d58b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "==================================\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "cancer_labels = cancer.target\n",
    "print(cancer_data)\n",
    "print(\"==================================\")\n",
    "print(cancer_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53899e1",
   "metadata": {},
   "source": [
    "- 학습을 위해 분류 전 마지막으로 Label Data 지정하고 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8928d557",
   "metadata": {},
   "source": [
    "### 3.3 모델학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d4b48",
   "metadata": {},
   "source": [
    "1) 학습 데이터 준비\n",
    "\n",
    " - 학습을 위해 train, test set으로 분리  \n",
    "   모델에 입력할 데이터는 X, 비교할 정답 데이터는 y, 학습 데이터는 train, 테스트 데이터는 test로 분리  \n",
    "   data_size=0.2로 테스트용 데이터는 20%로 구성하고 random_state 값을 통해 분리할 때 데이터를 랜덤 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "37b3c687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (455,)\n",
      "(114, 30) (114,)\n",
      "Counter({1: 357, 0: 212})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data, cancer_label, test_size=0.2, random_state=15)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae3d67",
   "metadata": {},
   "source": [
    " - .shape로 데이터가 잘 나뉘었는지 확인(총 569개의 데이터가 455, 114개로 잘 나뉨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a51e2f3",
   "metadata": {},
   "source": [
    "2) 모델 적용\n",
    "\n",
    " - 어떤 모델이 적합한지 확인이 필요하므로 5가지 모델을 다 적용해 본다.   \n",
    "   (Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression)   \n",
    " - 모델의 평가는 sklearn의 Classification_report를 import하여 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bf530e",
   "metadata": {},
   "source": [
    "1) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6029acde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92        39\n",
      "           1       0.94      0.99      0.96        75\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree_cancer = DecisionTreeClassifier(random_state=22)\n",
    "decision_tree_cancer.fit(X_train, y_train)\n",
    "y_pred = decision_tree_cancer.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38284913",
   "metadata": {},
   "source": [
    "2) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "273eb07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        39\n",
      "           1       0.94      0.97      0.95        75\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_cancer = RandomForestClassifier(random_state=32)\n",
    "random_forest_cancer.fit(X_train, y_train)\n",
    "y_pred = random_forest_cancer.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed659c",
   "metadata": {},
   "source": [
    "3) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dc477de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78        39\n",
      "           1       0.85      0.97      0.91        75\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.89      0.82      0.84       114\n",
      "weighted avg       0.88      0.87      0.86       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model_cancer = svm.SVC()\n",
    "svm_model_cancer.fit(X_train, y_train)\n",
    "y_pred = svm_model_cancer.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9fa1e",
   "metadata": {},
   "source": [
    "4) SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63f6a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.75        39\n",
      "           1       0.92      0.76      0.83        75\n",
      "\n",
      "    accuracy                           0.80       114\n",
      "   macro avg       0.79      0.82      0.79       114\n",
      "weighted avg       0.83      0.80      0.80       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd_model_cancer = SGDClassifier()\n",
    "sgd_model_cancer.fit(X_train, y_train)\n",
    "y_pred = sgd_model_cancer.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0cf26",
   "metadata": {},
   "source": [
    "5) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "744eb28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        39\n",
      "           1       0.91      0.93      0.92        75\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.88      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losistic_model_cancer = LogisticRegression(max_iter=5000)\n",
    "losistic_model_cancer.fit(X_train, y_train)\n",
    "y_pred = losistic_model_cancer.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce5e66",
   "metadata": {},
   "source": [
    "### 3.4 결과분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca6546",
   "metadata": {},
   "source": [
    "classification report에 아래와 같은 내용들이 나온다.\n",
    "\n",
    " - Precision은 Confusion matrix에서 TP / TP + FP이다.(양성으로 예측한 샘플 중 실제 양성인 비율)\n",
    " - Recall은 TP / TP + FN(실제 양성 중 양성이라고 예측한 비율)\n",
    " - Accuracy는 TP + TN / TN + TP + FN + FP (전체 샘플 중 맞게 예측한 샘플 수의 비율)\n",
    " - F1-score는 precision과 recall의 가중 조화평균이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38998719",
   "metadata": {},
   "source": [
    "- cancer의 진단에서 가장 중요하게 봐야할 부분은 recall이라고 생각한다. 실제 malignant를 benign으로 해석하면  \n",
    "환자의 생명과 직결되는 큰 문제가 생기기 때문이다. 이에 recall 값을 비교하면 Decision Tree, Random forest,  \n",
    " SGD Classifier를 우선적으로 고려할 수 있다. 이후 Accuracy로 탈락시킬 모델은 - SGD Classifier로 정확도 90%를  \n",
    " 넘지 못해 Decision Tree, Random forest 모델에 비해 터무니 없이 낮다.  \n",
    "    \n",
    "    \n",
    "- Stochastic Gradient Descent는 digits, wine 분류에서도 불안정한 정확도를 보여서 마찬가지로 반복 수행함  \n",
    "  마찬가지로 20번 수행했을 때 정확도가 들쑥날쑥한 모습(0.60~0.84)을 보여준다.\n",
    "  SGD는 사용하기 어려울 것으로 판단됨 (정확도가 낮아 우선 탈락)\n",
    "  \n",
    "    \n",
    "- 앞서 wine 분류와 동일하게 Logistic Regression의 반복 횟수(iter) 42회 미만일 때는 성능 편차가 크지만,   \n",
    "  42회를 넘어갈수록 성능 변화가 미미함 따라서 가성비 있는 훈련은 50~60회 가량으로 판단되며,  \n",
    "  iterations reached limit warning message를 보고 싶지 않으면 max_iter 값을 5000정도 주어 훈련하는 것을 권장   \n",
    "  (정확도가 낮아 우선 탈락)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
